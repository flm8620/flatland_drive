# Configuration for ConvNet-based imitation learning on Flatland driving data

# Data settings
data:
  h5_file_path: "human_data/human_data_250928-3.h5"
  train_split: 0.8
  split_seed: 42  # Random seed for reproducible train/val episode splits
  # ConvNet filtering parameters (more lenient than ACT since we predict single actions)
  max_no_op_ratio: 1.0    # Allow segments with any no-op ratio (since chunk_size=1, ratio is 0 or 1)
  stride: 1  # Every timestep (dense sampling for single-step prediction)
  # Allow some no-op samples for ConvNet (important for class balance)
  no_op_filter_percentage: 0.7  # 70% of segments must meet filtering criteria, 30% can be no-op

# Model architecture
model:
  action_dim: 9
  hidden_dim: 128  # Much smaller than ACT's 256
  dropout: 0.1

# Training parameters
training:
  epochs: 100  # Fewer epochs than ACT since simpler model
  batch_size: 256  # Larger batch size since model is smaller
  lr: 3e-4  # Slightly higher learning rate
  weight_decay: 1e-4
  num_workers: 4  # Can use more workers since no complex data processing
  # Learning rate schedule
  warmup_ratio: 0.1  # 10% of total training for warmup (similar to ACT)
  # Focal loss parameters to handle class imbalance
  focal_alpha: 1.0
  focal_gamma: 2.0

# Logging and checkpoints
logging:
  output_dir: "outputs_imi"
  save_interval: 10  # Save checkpoint every N epochs

# Run configuration
run_name: null  # If null, will use current timestamp

# Performance monitoring
enable_timer: false  # Enable detailed timing reports

# Hydra settings
hydra:
  run:
    dir: outputs/convnet_training/${now:%Y-%m-%d_%H-%M-%S}
