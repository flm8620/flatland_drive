# @package _global_

# PPO training configuration

defaults:
  - env_config  # Include environment config

# PPO-specific environment parameters
env:
  num_envs: 32
  render_dir: ${hydra:run.dir}/viz
  
  # Curriculum learning for PPO training
  curriculum:
    - min_start_goal_dist: 10
      max_start_goal_dist: 20
      hitwall_cost: -10.0
      until_rollout: 50
    - min_start_goal_dist: 20
      max_start_goal_dist: 50
      hitwall_cost: -20.0
      until_rollout: 100
    - min_start_goal_dist: 30
      max_start_goal_dist: 100
      hitwall_cost: -30.0
      until_rollout: 300
    - min_start_goal_dist: 50
      max_start_goal_dist: 200
      hitwall_cost: -50.0
      until_rollout: 999999

# Training hyperparameters
train:
  resume: true
  lr: 3e-4
  gamma: 0.999
  gae_lambda: 0.99
  rollout_steps: 2048
  ppo_epochs: 4
  minibatch_size: 128
  clip_eps: 0.2
  max_steps: 2000
  save_every: 5
  num_rollouts: 2000 
  fp16: false

# Model selection
model:
  type: conv   # Options: 'vit' or 'conv'
  vit_embed_dim: 128
  conv_out_dim: 384

# Logging
log_dir: ${hydra:run.dir}/tb
run_name: ${now:%Y-%m-%d_%H-%M-%S}
enable_timer: true

# Seed
seed: 42

# Output directory
output_dir: outputs

# Debug and snapshot loading
load_actor_path: null
load_critic_path: null
