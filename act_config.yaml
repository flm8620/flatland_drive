# Configuration for ACT training on Flatland driving data

# Data settings
data:
  h5_file_path: "human_data/human_data_clean.h5"
  train_split: 0.8

# Model architecture
model:
  action_dim: 9  # 0-8 directional actions (no action + 8 directions)
  chunk_size: 32  # Number of future actions to predict per observation
  hidden_dim: 256
  nhead: 8
  num_encoder_layers: 4  # Encoder layers for observation processing
  num_decoder_layers: 6  # Decoder layers for action sequence generation
  dim_feedforward: 1024
  dropout: 0.1

# Training parameters
training:
  epochs: 200
  batch_size: 16  # Adjust based on GPU memory
  lr: 1e-4
  weight_decay: 1e-4
  num_workers: 4

# Logging and checkpoints
logging:
  log_dir: "runs/act_flatland"
  save_dir: "checkpoints/act_flatland" 
  save_interval: 10  # Save checkpoint every N epochs

# Hydra settings
hydra:
  run:
    dir: outputs/act_training/${now:%Y-%m-%d_%H-%M-%S}
